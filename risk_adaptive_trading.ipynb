{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trading System Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trader():\n",
    "    def __init__(self, stock_exchange, capital):\n",
    "        self.initial_capital = capital\n",
    "        self.cash = capital\n",
    "        self.portfolio = {}\n",
    "        self.exchange = stock_exchange\n",
    "        self.transaction_fees = 0.002\n",
    "        \n",
    "    def buy(self, counter, size_to_buy):\n",
    "        # checks if counter even exists\n",
    "        if counter in self.exchange.get_available_counters():\n",
    "            # enough cash?\n",
    "            if self.exchange.get_price(counter) * size_to_buy <= self.cash:\n",
    "                self.cash -= (self.exchange.get_price(counter) * size_to_buy * (1+self.transaction_fees))\n",
    "                if counter not in self.portfolio.keys():\n",
    "                    self.portfolio[counter] = size_to_buy\n",
    "                else:\n",
    "                    self.portfolio[counter] += size_to_buy\n",
    "            else:\n",
    "                raise ValueError('Not enough money')\n",
    "            pass\n",
    "\n",
    "\n",
    "    def sell(self, counter, size_to_sell):\n",
    "        # checks if shares exists in trader's portfolio\n",
    "        if counter in self.portfolio.keys():\n",
    "            # enough shares?\n",
    "            if size_to_sell > 0:\n",
    "                if self.portfolio[counter] >= size_to_sell:\n",
    "                    #print(\"Cash before:\")\n",
    "                    #print(self.cash)\n",
    "                    self.portfolio[counter] -= size_to_sell\n",
    "                    #print(\"Cash gotten:\")\n",
    "                    #print(self.exchange.get_price(counter) * size_to_sell * (1-self.transaction_fees))\n",
    "                    self.cash += (self.exchange.get_price(counter) * size_to_sell * (1-self.transaction_fees))\n",
    "                    #print(\"Cash now:\")\n",
    "                    #print(self.cash)\n",
    "                else:\n",
    "                    raise ValueError('Not enough shares to sell')\n",
    "    def get_portfolio_value(self):\n",
    "        value = self.cash;\n",
    "        for i in self.portfolio.keys():\n",
    "            value = value + (self.portfolio[i] * self.exchange.get_price(i))\n",
    "            #print('Date: ' + str(self.exchange.get_date()))\n",
    "        return value\n",
    "    \n",
    "    def get_portfolio(self):\n",
    "        return self.portfolio\n",
    "    \n",
    "    def get_max_stocks_purchasable(self, counter, funds):\n",
    "        return math.floor(funds/((1+self.transaction_fees) * self.exchange.get_price(counter)))\n",
    "    \n",
    "    def get_cash(self):\n",
    "        return self.cash\n",
    "    \n",
    "    def get_initial_capital(self):\n",
    "        return self.initial_capital\n",
    "    \n",
    "    def get_profits(self):\n",
    "        return self.get_portfolio_value() - self.get_initial_capital()\n",
    "    \n",
    "    @staticmethod\n",
    "    def copy(trader):\n",
    "        new_trader = Trader(trader.exchange, trader.get_initial_capital())\n",
    "        new_trader.cash = trader.get_cash()\n",
    "        \n",
    "        if stock_symbol in trader.get_portfolio().keys():\n",
    "            new_trader.portfolio = { stock_symbol : trader.get_portfolio()[stock_symbol]}\n",
    "        else:\n",
    "            new_trader.portfolio = {}\n",
    "        new_trader.transaction_fees = 0.00175#0.002\n",
    "        return new_trader\n",
    "            \n",
    "class Stock_Exchange():\n",
    "    def __init__(self, counters):\n",
    "        self.available_counters = counters # takes a list, ['aig', 'bac', 'c', 'googl_v3', 'gs', 'jpm']\n",
    "        self.data = {}\n",
    "        self.date = datetime.datetime.strptime('2000-01-01', \"%Y-%m-%d\").date()\n",
    "        self.last_date = datetime.datetime.strptime('2020-01-01', \"%Y-%m-%d\").date()\n",
    "        for i in self.available_counters:\n",
    "            data = pd.read_csv('data/' + i + '.csv')\n",
    "            data['Date'] = data['Date'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%d\").date())\n",
    "            self.data[i] = data\n",
    "            if(self.date < self.data[i][\"Date\"][0]):\n",
    "                self.date = self.data[i][\"Date\"][0]\n",
    "                \n",
    "            if(self.last_date > self.data[i][\"Date\"].iloc[-1]):\n",
    "                self.last_date = self.data[i][\"Date\"].iloc[-1]\n",
    "        \n",
    "        self.first_date = self.date\n",
    "        \n",
    "    def get_available_counters(self):\n",
    "        return self.available_counters\n",
    "    \n",
    "    def get_price(self, counter):\n",
    "        if(counter in self.available_counters):\n",
    "            #print(self.data)\n",
    "            val = self.data[counter].loc[self.data[counter]['Date'] == self.date]['Close']\n",
    "            return list(val)[0]\n",
    "        else:\n",
    "            raise ValueError('Counter does not exist in exchange')\n",
    "            \n",
    "    def set_date(self, date, date_format):\n",
    "        date = datetime.datetime.strptime(date, date_format).date()\n",
    "        self.date = date\n",
    "        \n",
    "    def set_date(self, date):\n",
    "        self.date = date\n",
    "    \n",
    "    def get_date(self):\n",
    "        return self.date\n",
    "            \n",
    "    def next_day(self):\n",
    "        self.date = self.date + datetime.timedelta(days=1)\n",
    "        repeat = True\n",
    "        while repeat:\n",
    "            repeat = False\n",
    "            '''for i in self.available_counters:\n",
    "                if not (self.data[i]['Date'] == self.date).any():\n",
    "                    #print(self.date)\n",
    "                    #print('is a weekend')\n",
    "                    self.date = self.date + datetime.timedelta(days=1)\n",
    "                    repeat = True\n",
    "                    break\n",
    "            '''\n",
    "            if self.date.weekday() >= 5:\n",
    "                self.date = self.date + datetime.timedelta(days=1)\n",
    "                repeat = True\n",
    "    def get_last_date(self):\n",
    "        return self.last_date\n",
    "    \n",
    "    def get_first_date(self):\n",
    "        return self.first_date\n",
    "    \n",
    "    def reset(self):\n",
    "        self.date = self.first_date\n",
    "    \n",
    "    def fast_forward(self):\n",
    "        self.date = self.last_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import math\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_levels = [-1, -0.5, -0.2, 0, 0.2, 0.5, 1]\n",
    "\n",
    "ACTION_LONG = 0\n",
    "ACTION_CLOSE = 1\n",
    "\n",
    "'''\n",
    "PARAMETERS TO CHANGE\n",
    "'''\n",
    "start_price_index = 2125 #2125 # this should be (25 + start_state_num from the risk_q_learning file)\n",
    "duration = 700 # this should be the same as the duration in risk_q_learning\n",
    "comparison_offset = 25 # this should be the same as window_size in risk_adaptive_trading_data_generation\n",
    "stock_symbol = 'bac'\n",
    "capital = 10000\n",
    "''''''\n",
    "\n",
    "trading_patterns_dir = './trading_patterns/'\n",
    "trading_patterns = []\n",
    "trading_patterns_dict = {}\n",
    "for level in risk_levels:    \n",
    "    actions_data = pd.read_csv(trading_patterns_dir + stock_symbol + '_' + str(level) + '_' + str(start_price_index) + '_to_' + str(start_price_index + duration) + '.csv')\n",
    "    actions_data['Date'] = actions_data['Date'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%d\").date())\n",
    "    trading_patterns_dict[level] = {}\n",
    "    for index, row in actions_data[start_price_index:start_price_index+duration].iterrows():\n",
    "        trading_patterns_dict[level][row['Date']] = row['trading_action']\n",
    "    #actions_data[['Date', 'trading_action']][start_price_index:start_price_index+duration].reset_index(drop=True)\n",
    "    trading_patterns.append(actions_data[['Date', 'trading_action']][start_price_index:start_price_index+duration].reset_index(drop=True))\n",
    "\n",
    "exchange = Stock_Exchange([stock_symbol])\n",
    "secondary_exchange = Stock_Exchange([stock_symbol])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK PROFITS OF EACH RISK LEVEL\n",
    "for risk_action_tuple in zip(risk_levels, trading_patterns):\n",
    "    gupta = Trader(exchange, capital)\n",
    "    print('Risk Level: ' + str(risk_action_tuple[0]))\n",
    "    for index, row in risk_action_tuple[1][comparison_offset:].iterrows():\n",
    "        exchange.set_date(row['Date'])\n",
    "        if row['trading_action'] == ACTION_LONG:\n",
    "            stocks_to_buy = gupta.get_max_stocks_purchasable(stock_symbol, gupta.get_cash())\n",
    "            gupta.buy(stock_symbol, stocks_to_buy)\n",
    "        elif row['trading_action'] == ACTION_CLOSE:\n",
    "            if stock_symbol in gupta.get_portfolio().keys():\n",
    "                gupta.sell(stock_symbol, gupta.get_portfolio()[stock_symbol])\n",
    "            \n",
    "    print(gupta.get_portfolio_value()- gupta.initial_capital)\n",
    "    \n",
    "    exchange.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find best model on this date\n",
    "def find_best_model(date, window):\n",
    "    best_model_i = None\n",
    "    best_profit = None\n",
    "    for i in range(len(trading_patterns)):\n",
    "        this_date_index = trading_patterns[0].index[trading_patterns[0]['Date'] == date].tolist()[0]\n",
    "        profit = calculate_profit(trading_patterns[i][this_date_index-window:this_date_index])\n",
    "        if best_model_i is None or profit > best_profit:\n",
    "            best_profit = profit\n",
    "            best_model_i = i\n",
    "    return best_model_i\n",
    "            \n",
    "            \n",
    "def calculate_profit(a_trading_pattern):\n",
    "    mock_trader = Trader(secondary_exchange, capital)\n",
    "    trade(a_trading_pattern, mock_trader)\n",
    "    return mock_trader.get_portfolio_value() - mock_trader.get_initial_capital()\n",
    "    \n",
    "\n",
    "def trade(a_trading_pattern, mock_trader):\n",
    "    for index, row in a_trading_pattern.iterrows():\n",
    "        secondary_exchange.set_date(row['Date'])\n",
    "        if row['trading_action'] == ACTION_LONG:\n",
    "            stocks_to_buy = mock_trader.get_max_stocks_purchasable(stock_symbol, mock_trader.get_cash())\n",
    "            mock_trader.buy(stock_symbol, stocks_to_buy)\n",
    "        elif row['trading_action'] == ACTION_CLOSE:\n",
    "            if stock_symbol in mock_trader.get_portfolio().keys():\n",
    "                mock_trader.sell(stock_symbol, mock_trader.get_portfolio()[stock_symbol])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gupta's Risk Adaptive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exchange.reset()\n",
    "gupta = Trader(exchange, capital)\n",
    "gupta_window = 21\n",
    "for i in range(comparison_offset,len(trading_patterns[0])):\n",
    "    exchange.set_date(trading_patterns[0]['Date'][i])\n",
    "    best_risk_model_i = find_best_model(trading_patterns[0]['Date'][i], window = gupta_window)\n",
    "    action = trading_patterns[best_risk_model_i]['trading_action'][i]\n",
    "    if action == ACTION_LONG:\n",
    "            stocks_to_buy = gupta.get_max_stocks_purchasable(stock_symbol, gupta.get_cash())\n",
    "            gupta.buy(stock_symbol, stocks_to_buy)\n",
    "    elif action == ACTION_CLOSE:\n",
    "        if stock_symbol in gupta.get_portfolio().keys():\n",
    "            gupta.sell(stock_symbol, gupta.get_portfolio()[stock_symbol])\n",
    "    print(str(i) + '/' + str(len(trading_patterns[0])))\n",
    "print('Profit:' + str(gupta.get_portfolio_value()-gupta.get_initial_capital()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_processed_data(technical_indicated_file):\n",
    "    std_span = 10\n",
    "    # Data reading and preprocessing\n",
    "    data =  pd.read_csv(technical_indicated_file)\n",
    "    data['Date'] = data['Date'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%d\").date())\n",
    "    small_data = data\n",
    "    x = small_data['Date']\n",
    "\n",
    "    # Calculating std (sigma)\n",
    "    std = pd.DataFrame()\n",
    "    std['Date'] = small_data['Date']\n",
    "    std['Rolling-STD'] = small_data[\"EMA-12-Close\"].rolling(std_span).std()\n",
    "    \n",
    "    # PCT_CHANGE\n",
    "    small_data['Pct_Change'] = small_data['EMA-12-Close'].pct_change()\n",
    "    small_data['Abs_Pct_Change'] = abs(small_data['EMA-12-Close'].pct_change())\n",
    "    small_data['Pct_Change_Vol'] = small_data['EMA-12-Volume'].pct_change()\n",
    "\n",
    "    \"\"\"\n",
    "    Calculating volatility\n",
    "    \"\"\"\n",
    "    crashes_k = pd.DataFrame()\n",
    "    crashes_k[\"Date\"] = small_data[\"Date\"]\n",
    "    crashes_k[\"crashes_k\"] = small_data['neg_and_above_threshold'] * 1\n",
    "\n",
    "\n",
    "    \"\"\" \n",
    "    Using PPO for Timing\n",
    "    \"\"\"\n",
    "    # neg_k = 1 when trigger goes on top of PPO line (Red)\n",
    "    # pos_k = 1 when trigger goes below PPO line (Green)\n",
    "\n",
    "    d = (small_data[\"PPO\"] - small_data[\"PPO-EMA-Trigger\"])\n",
    "\n",
    "    # PPO Buy and Sell Signals\n",
    "    ppo_above = pd.Series(np.nan, index=list(range(0,small_data.shape[0])))\n",
    "    ppo_below = pd.Series(np.nan, index=list(range(0,small_data.shape[0])))\n",
    "    ppo_buy_signals = pd.Series(np.nan, index=list(range(0,small_data.shape[0])))\n",
    "    ppo_sell_signals = pd.Series(np.nan, index=list(range(0,small_data.shape[0])))\n",
    "\n",
    "\n",
    "    d = (small_data[\"PPO\"] - small_data[\"PPO-EMA-Trigger\"])\n",
    "    for i in range(1, len(d) - 1):\n",
    "        if d[i] * d[i - 1] < 0.:\n",
    "            # crossover at i\n",
    "            if(d[i] > 0.):\n",
    "                ppo_above[i] = small_data.loc[i, \"PPO-EMA-Trigger\"]\n",
    "                ppo_buy_signals[i] = small_data.loc[i, \"Date\"]\n",
    "            else:\n",
    "                ppo_below[i] = small_data.loc[i, \"PPO-EMA-Trigger\"]\n",
    "                ppo_sell_signals[i] = small_data.loc[i, \"Date\"]\n",
    "\n",
    "    #ppo_buy_signals.to_csv(folder + counter + \"-ppo-buy.csv\", index=False)\n",
    "    #ppo_sell_signals.to_csv(folder + counter + \"-ppo-sell.csv\", index=False)\n",
    "\n",
    "\n",
    "    # Caclulating ppo_k\n",
    "    ppo_k = pd.DataFrame()\n",
    "\n",
    "    # Populating std\n",
    "    ppo_k['std'] = std['Rolling-STD']\n",
    "\n",
    "    # Filling pos_k and neg_k with 1\n",
    "    ppo_k[\"Date\"] = small_data[\"Date\"]\n",
    "    ppo_k[\"pos_k\"] = pd.Series(np.nan, index=list(range(0,ppo_k.shape[0])))\n",
    "    ppo_k[\"pos_k\"].loc[ppo_k[\"Date\"] == ppo_buy_signals] = 1\n",
    "\n",
    "    ppo_k[\"neg_k\"] = pd.Series(np.nan, index=list(range(0,ppo_k.shape[0])))\n",
    "    ppo_k[\"neg_k\"].loc[ppo_k[\"Date\"] == ppo_sell_signals] = 1\n",
    "    assert(all(std[\"Date\"] == ppo_k[\"Date\"]))\n",
    "\n",
    "    # Filling ppo_k dataframe with t to help speed up calculation during half-life\n",
    "    # Init t as 0 for dates where ppo signals\n",
    "    ppo_k[\"pos_k_t\"] = pd.Series(np.nan, index=list(range(0,ppo_k.shape[0])))\n",
    "    ppo_k[\"pos_k_t\"].loc[ppo_k[\"pos_k\"] == 1] = 0\n",
    "\n",
    "    ppo_k[\"neg_k_t\"] = pd.Series(np.nan, index=list(range(0,ppo_k.shape[0])))\n",
    "    ppo_k[\"neg_k_t\"].loc[ppo_k[\"neg_k\"] == 1] = 0\n",
    "\n",
    "    # Identify first pos_k and first neg_k\n",
    "    first_pos_k_index = ppo_k['pos_k'].idxmax()\n",
    "    first_neg_k_index = ppo_k['neg_k'].idxmax()\n",
    "\n",
    "    # Populating ppo t values \n",
    "    tmp = ppo_k.copy()\n",
    "    i = 0\n",
    "    while ppo_k[\"pos_k_t\"][first_pos_k_index:].isnull().values.any() or ppo_k[\"neg_k_t\"][first_neg_k_index:].isnull().values.any():\n",
    "        i+=1\n",
    "        tmp = tmp.shift()\n",
    "        ppo_k[\"pos_k_t\"].loc[(tmp[\"pos_k\"] == 1) & (ppo_k[\"pos_k_t\"].isnull())] = i\n",
    "        ppo_k[\"neg_k_t\"].loc[(tmp[\"neg_k\"] == 1) & (ppo_k[\"neg_k_t\"].isnull())] = i\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Using RSI for Timing\n",
    "    \"\"\"\n",
    "    # neg_k = 1 when above 70 (Overbought)\n",
    "    # pos_k = 1 when above 30 (Oversold)\n",
    "    overbought = pd.Series(np.nan, index=list(range(0,small_data.shape[0])))\n",
    "    oversold = pd.Series(np.nan, index=list(range(0,small_data.shape[0])))\n",
    "    rsi_buy_signals = pd.Series(np.nan, index=list(range(0,small_data.shape[0])))\n",
    "    rsi_sell_signals = pd.Series(np.nan, index=list(range(0,small_data.shape[0])))\n",
    "\n",
    "    d_overbought = (70 - small_data[\"RSI\"])\n",
    "    for i in range(1, len(d_overbought) - 1):\n",
    "        '''if d_overbought[i] * d_overbought[i - 1] < 0.:\n",
    "                # crossover at i\n",
    "                if d_overbought[i] < 0.:\n",
    "                    rsi_sell_signals[i] = small_data.loc[i, \"Date\"]\n",
    "                    overbought[i] = 70 #small_data.loc[i, \"RSI\"]'''\n",
    "        if(d_overbought[i] < 0):\n",
    "            rsi_sell_signals[i] = small_data.loc[i, \"Date\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    d_oversold = (30 - small_data[\"RSI\"])\n",
    "    for i in range(1, len(d_oversold) - 1):\n",
    "        '''if d_oversold[i] * d_oversold[i - 1] < 0.:\n",
    "                # crossover at i\n",
    "                if d_oversold[i] > 0.:\n",
    "                    rsi_buy_signals[i] = small_data.loc[i, \"Date\"]\n",
    "                    oversold[i] = 30 #small_data.loc[i, \"RSI\"]'''\n",
    "        if(d_oversold[i] > 0):\n",
    "            rsi_buy_signals[i] = small_data.loc[i, \"Date\"]\n",
    "\n",
    "\n",
    "\n",
    "    # Caclulating rsi_k\n",
    "    rsi_k = pd.DataFrame()\n",
    "\n",
    "    # Populating std\n",
    "    rsi_k['std'] = std['Rolling-STD']\n",
    "\n",
    "    # Filling pos_k and neg_k with 1\n",
    "    rsi_k[\"Date\"] = small_data[\"Date\"]\n",
    "    rsi_k[\"pos_k\"] = pd.Series(np.nan, index=list(range(0,rsi_k.shape[0])))\n",
    "    rsi_k[\"pos_k\"].loc[rsi_k[\"Date\"] == rsi_buy_signals] = 1\n",
    "\n",
    "    rsi_k[\"neg_k\"] = pd.Series(np.nan, index=list(range(0,rsi_k.shape[0])))\n",
    "    rsi_k[\"neg_k\"].loc[rsi_k[\"Date\"] == rsi_sell_signals] = 1\n",
    "    assert(all(std[\"Date\"] == rsi_k[\"Date\"]))\n",
    "\n",
    "\n",
    "    # Filling rsi_k dataframe with t to help speed up calculation during half-life\n",
    "    # Init t as 0 for dates where rsi signals\n",
    "    rsi_k[\"pos_k_t\"] = pd.Series(np.nan, index=list(range(0,rsi_k.shape[0])))\n",
    "    rsi_k[\"pos_k_t\"].loc[rsi_k[\"pos_k\"] == 1] = 0\n",
    "\n",
    "    rsi_k[\"neg_k_t\"] = pd.Series(np.nan, index=list(range(0,rsi_k.shape[0])))\n",
    "    rsi_k[\"neg_k_t\"].loc[rsi_k[\"neg_k\"] == 1] = 0\n",
    "\n",
    "    # Identify first pos_k and first neg_k\n",
    "    first_pos_k_index = rsi_k['pos_k'].idxmax()\n",
    "    first_neg_k_index = rsi_k['neg_k'].idxmax()\n",
    "\n",
    "    # Populating rsi t values \n",
    "    tmp = rsi_k.copy()\n",
    "    i = 0\n",
    "    while rsi_k[\"pos_k_t\"][first_pos_k_index:].isnull().values.any() or rsi_k[\"neg_k_t\"][first_neg_k_index:].isnull().values.any():\n",
    "        i+=1\n",
    "        tmp = tmp.shift()\n",
    "        rsi_k[\"pos_k_t\"].loc[(tmp[\"pos_k\"] == 1) & (rsi_k[\"pos_k_t\"].isnull())] = i\n",
    "        rsi_k[\"neg_k_t\"].loc[(tmp[\"neg_k\"] == 1) & (rsi_k[\"neg_k_t\"].isnull())] = i\n",
    "    \n",
    "    return ppo_k, rsi_k, crashes_k, small_data, ppo_buy_signals, ppo_sell_signals\n",
    "\n",
    "def get_combined_k(decay_alpha_ppo, decay_alpha_rsi, ppo_k, rsi_k, technical_data, crashes_k):\n",
    "    \"\"\"\n",
    "    Generate combined pos_k and neg_k based on given decay_alpha\n",
    "    \"\"\"\n",
    "    \n",
    "    assert(len(ppo_k) == len(rsi_k) and len(technical_data) == len(crashes_k) and len(technical_data == len(ppo_k)))\n",
    "    \n",
    "    # Decay ppo_k using half-life \n",
    "    ppo_k[\"pos_k_hl\"] = ppo_k[\"pos_k\"]\n",
    "    ppo_k[\"neg_k_hl\"] = ppo_k[\"neg_k\"]\n",
    "\n",
    "    tmp = (-1 * decay_alpha_ppo * technical_data['Abs_Pct_Change'])\n",
    "    \n",
    "    ppo_k[\"pos_k_hl\"] = (math.e ** (tmp * ppo_k[\"pos_k_t\"])) # * 1.0 (omitted) where 1.0 is the N(0)\n",
    "    ppo_k[\"neg_k_hl\"] = (math.e ** (tmp * ppo_k[\"neg_k_t\"])) # * 1.0 (omitted) where 1.0 is the N(0)\n",
    "    \n",
    "    '''ppo_k[\"pos_k_hl\"] = 1.0 * (math.e ** (-1 * decay_alpha_ppo * (technical_data['pct_change_vol'] * 1000) * technical_data['pct_change'] * ppo_k[\"pos_k_t\"])) \n",
    "    ppo_k[\"neg_k_hl\"] = 1.0 * (math.e ** (-1 * decay_alpha_ppo * (technical_data['pct_change_vol'] * 1000) * technical_data['pct_change'] * ppo_k[\"neg_k_t\"]))\n",
    "    '''\n",
    "    # Decay rsi_k using half-life \n",
    "    rsi_k[\"pos_k_hl\"] = rsi_k[\"pos_k\"]\n",
    "    rsi_k[\"neg_k_hl\"] = rsi_k[\"neg_k\"]\n",
    "    \n",
    "    tmp = (-1 * decay_alpha_rsi * technical_data['Abs_Pct_Change'])\n",
    "\n",
    "    rsi_k[\"pos_k_hl\"] = (math.e ** (tmp * rsi_k[\"pos_k_t\"])) # * 1.0 (omitted) where 1.0 is the N(0)\n",
    "    rsi_k[\"neg_k_hl\"] = (math.e ** (tmp * rsi_k[\"neg_k_t\"])) # * 1.0 (omitted) where 1.0 is the N(0)\n",
    "    \n",
    "    '''rsi_k[\"pos_k_hl\"] = 1.0 * (math.e ** (-1 * decay_alpha_rsi * (technical_data['pct_change_vol'] * 1000) * technical_data['pct_change'] * rsi_k[\"pos_k_t\"])) \n",
    "    rsi_k[\"neg_k_hl\"] = 1.0 * (math.e ** (-1 * decay_alpha_rsi * (technical_data['pct_change_vol'] * 1000) * technical_data['pct_change'] * rsi_k[\"neg_k_t\"]))\n",
    "    '''\n",
    "    #print(rsi_k[\"pos_k_hl\"])\n",
    "    #rsi_k.to_csv(folder + counter + \"-rsi.csv\")\n",
    "    #ppo_k.to_csv(folder + counter + \"-ppo.csv\")\n",
    "\n",
    "    # Combining PPO_K and RSI_K\n",
    "    assert(all(ppo_k[\"Date\"] == rsi_k[\"Date\"]) and all(ppo_k[\"Date\"] == technical_data[\"Date\"]) and all(crashes_k[\"Date\"] == ppo_k[\"Date\"]))\n",
    "    \n",
    "    combined_k = pd.DataFrame()\n",
    "    combined_k[\"Date\"] = technical_data[\"Date\"]\n",
    "    combined_k[\"pos_k_hl\"] = ppo_k[\"pos_k_hl\"].fillna(0) * rsi_k[\"pos_k_hl\"].fillna(0)\n",
    "    combined_k[\"neg_k_hl\"] = pow(ppo_k[\"neg_k_hl\"].fillna(0) * rsi_k[\"neg_k_hl\"].fillna(0), 1-crashes_k[\"crashes_k\"])\n",
    "    #combined_k[\"neg_k_hl\"] = ppo_k[\"neg_k_hl\"].fillna(0) * rsi_k[\"neg_k_hl\"].fillna(0)\n",
    "\n",
    "\n",
    "    # Using ADX & DMI\n",
    "    # Irrespective of whether the trader takes a long or short position, \n",
    "    # the ADX should be over 25 when the crossover occurs to confirm the trend’s strength. \n",
    "    combined_k[\"pos_k_hl_copy\"] = combined_k[\"pos_k_hl\"]\n",
    "    combined_k[\"neg_k_hl_copy\"] = combined_k[\"neg_k_hl\"]\n",
    "\n",
    "    assert(all(combined_k[\"Date\"]==technical_data[\"Date\"]))\n",
    "\n",
    "    \n",
    "    '''combined_k[\"neg_k_hl_copy\"].loc[(technical_data[\"NEG_DI14\"] > technical_data[\"POS_DI14\"]) & (technical_data[\"ADX\"] >= 40)] = combined_k[\"neg_k_hl_copy\"] * 1.0\n",
    "    combined_k[\"neg_k_hl_copy\"].loc[(technical_data[\"NEG_DI14\"] > technical_data[\"POS_DI14\"]) & (technical_data[\"ADX\"] >= 30) & (technical_data[\"ADX\"] < 40)] = combined_k[\"neg_k_hl_copy\"] * 0.5\n",
    "    combined_k[\"neg_k_hl_copy\"].loc[(technical_data[\"NEG_DI14\"] > technical_data[\"POS_DI14\"]) & (technical_data[\"ADX\"] >= 20) & (technical_data[\"ADX\"] < 30)] = combined_k[\"neg_k_hl_copy\"] * 0.25\n",
    "    \n",
    "    combined_k[\"pos_k_hl_copy\"].loc[(technical_data[\"POS_DI14\"] > technical_data[\"NEG_DI14\"]) & (technical_data[\"ADX\"] >= 40)] = combined_k[\"pos_k_hl_copy\"] * 1.0\n",
    "    combined_k[\"pos_k_hl_copy\"].loc[(technical_data[\"POS_DI14\"] > technical_data[\"NEG_DI14\"]) & (technical_data[\"ADX\"] >= 30) & (technical_data[\"ADX\"] < 40)] = combined_k[\"pos_k_hl_copy\"] * 0.5\n",
    "    combined_k[\"pos_k_hl_copy\"].loc[(technical_data[\"POS_DI14\"] > technical_data[\"NEG_DI14\"]) & (technical_data[\"ADX\"] >= 20) & (technical_data[\"ADX\"] < 30)] = combined_k[\"pos_k_hl_copy\"] * 0.25\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    \n",
    "    combined_k[\"neg_k_hl_copy\"].loc[(technical_data[\"NEG_DI14\"] > technical_data[\"POS_DI14\"]) & (technical_data[\"ADX\"] >= 20)] = combined_k[\"neg_k_hl\"] * 0.25\n",
    "    combined_k[\"neg_k_hl_copy\"].loc[(technical_data[\"NEG_DI14\"] > technical_data[\"POS_DI14\"]) & (technical_data[\"ADX\"] >= 30)] = combined_k[\"neg_k_hl\"] * 0.5\n",
    "    combined_k[\"neg_k_hl_copy\"].loc[(technical_data[\"NEG_DI14\"] > technical_data[\"POS_DI14\"]) & (technical_data[\"ADX\"] >= 40)] = combined_k[\"neg_k_hl\"] * 1.0\n",
    "    \n",
    "    combined_k[\"pos_k_hl_copy\"].loc[(technical_data[\"POS_DI14\"] > technical_data[\"NEG_DI14\"]) & (technical_data[\"ADX\"] >= 20)] = combined_k[\"pos_k_hl\"] * 0.25\n",
    "    combined_k[\"pos_k_hl_copy\"].loc[(technical_data[\"POS_DI14\"] > technical_data[\"NEG_DI14\"]) & (technical_data[\"ADX\"] >= 30)] = combined_k[\"pos_k_hl\"] * 0.5\n",
    "    combined_k[\"pos_k_hl_copy\"].loc[(technical_data[\"POS_DI14\"] > technical_data[\"NEG_DI14\"]) & (technical_data[\"ADX\"] >= 40)] = combined_k[\"pos_k_hl\"] * 1.0\n",
    "    \n",
    "    # Make it mutually exlusive\n",
    "    combined_k[\"neg_k_hl_copy\"].loc[(technical_data[\"POS_DI14\"] > technical_data[\"NEG_DI14\"]) & (technical_data[\"ADX\"] > 20)] = 0\n",
    "    combined_k[\"pos_k_hl_copy\"].loc[(technical_data[\"POS_DI14\"] < technical_data[\"NEG_DI14\"]) & (technical_data[\"ADX\"] > 20)] = 0\n",
    "\n",
    "    # Trend not strong enough\n",
    "    combined_k[\"neg_k_hl_copy\"].loc[(technical_data[\"ADX\"] < 20)] = 0\n",
    "    combined_k[\"pos_k_hl_copy\"].loc[(technical_data[\"ADX\"] < 20)] = 0\n",
    "\n",
    "    # combined_k.to_csv(folder + counter + \"-combined.csv\", index=False)\n",
    "    return combined_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_k(k):\n",
    "    closest_risk = None\n",
    "    closest_distance = None\n",
    "    for risk_level in risk_levels:\n",
    "        distance = abs(k-risk_level)\n",
    "        if closest_risk is None or distance < closest_distance:\n",
    "            closest_distance = distance\n",
    "            closest_risk = risk_level\n",
    "    return closest_risk\n",
    "\n",
    "def to_action(row):\n",
    "    date = row['Date']\n",
    "    risk_level = row['k']\n",
    "    tmp_pattern = trading_patterns_dict[risk_level]\n",
    "    return tmp_pattern[date]\n",
    "    #return tmp_pattern.loc[tmp_pattern['Date'] == date]['trading_action'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jing yang\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pandas\\core\\indexing.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "exchange.reset()\n",
    "jingyang = Trader(exchange, capital)\n",
    "folder = \"./temp/\"\n",
    "ppo_k, rsi_k, crashes_k, technical_data, tmp_ppo_buy_dates, tmp_ppo_sell_dates = get_processed_data(folder+stock_symbol+'-technical-indicated.csv')\n",
    "\n",
    "tmp_start_date = trading_patterns[0]['Date'][comparison_offset]\n",
    "tmp_end_date = trading_patterns[0]['Date'][duration-1]\n",
    "\n",
    "start_date_index = technical_data.index[technical_data['Date'] == tmp_start_date].tolist()[0] \n",
    "end_date_index = technical_data.index[technical_data['Date'] == tmp_end_date].tolist()[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PPO Trader\n",
    "\n",
    "ppo_buy_dates = pd.DataFrame(tmp_ppo_buy_dates[start_date_index:end_date_index+1])\n",
    "ppo_sell_dates = pd.DataFrame(tmp_ppo_sell_dates[start_date_index:end_date_index+1])\n",
    "\n",
    "assert(len(ppo_buy_dates) == duration - comparison_offset)\n",
    "assert(len(ppo_sell_dates) == duration - comparison_offset)\n",
    "\n",
    "ppo_buy_dates.columns = ['Date']\n",
    "ppo_sell_dates.columns = ['Date']\n",
    "\n",
    "ppo_buy_dates.dropna(inplace=True)\n",
    "ppo_sell_dates.dropna(inplace=True)\n",
    "\n",
    "ppo_buy_dates = ppo_buy_dates.reset_index(drop=True)\n",
    "ppo_sell_dates = ppo_sell_dates.reset_index(drop=True)\n",
    "\n",
    "\n",
    "exchange.reset()\n",
    "ppo_trader = Trader(exchange, capital)\n",
    "\n",
    "\n",
    "sell_index = 0\n",
    "for idx, row in ppo_buy_dates.iterrows():\n",
    "    exchange.set_date(row['Date'])\n",
    "    qty_to_buy = ppo_trader.get_max_stocks_purchasable(stock_symbol, ppo_trader.get_cash())\n",
    "    #print('Buying ' + str(qty_to_buy) + ' on ' + str(row['Date']) + ' for ' + str(exchange.get_price(stock_symbol)))\n",
    "    ppo_trader.buy(stock_symbol, qty_to_buy)\n",
    "    \n",
    "    while(True):\n",
    "        if sell_index >= ppo_sell_dates.shape[0]:\n",
    "            break\n",
    "        assert(row['Date']!=ppo_sell_dates.loc[sell_index]['Date'])\n",
    "        sell_date = ppo_sell_dates.loc[sell_index]['Date']\n",
    "        \n",
    "        # If sell date is later than the next buy date\n",
    "        if idx+1<ppo_buy_dates.shape[0] and sell_date > ppo_buy_dates.loc[idx+1]['Date']:\n",
    "            break\n",
    "        \n",
    "        # If sell date is earlier than the next buy date\n",
    "        if idx+1==ppo_buy_dates.shape[0] or sell_date < ppo_buy_dates.loc[idx+1]['Date']:\n",
    "            # If sell date is later than today\n",
    "            if sell_date > row['Date']:\n",
    "                exchange.set_date(sell_date)\n",
    "                qty_on_hand = 0\n",
    "                if(stock_symbol in ppo_trader.get_portfolio().keys()):\n",
    "                    qty_on_hand = ppo_trader.get_portfolio()[stock_symbol]\n",
    "                    \n",
    "                qty_to_sell = qty_on_hand\n",
    "                #print('Selling ' + str(qty_to_sell) + ' on ' + str(sell_date) + ' for ' + str(exchange.get_price(stock_symbol)))\n",
    "                ppo_trader.sell(stock_symbol, qty_to_sell)\n",
    "                sell_index+=1 \n",
    "                break\n",
    "            # If sell date is earlier than today\n",
    "            if sell_date < row['Date']:\n",
    "                sell_index+=1\n",
    "\n",
    "#fast forward\n",
    "exchange.set_date(tmp_end_date)\n",
    "print(ppo_trader.get_portfolio_value()-ppo_trader.get_initial_capital())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple search for optimal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for multiplier_ppo in range(1, 30, 1):     \\n    for multiplier_rsi in range(1, 30, 1): \\n        combined_k = get_combined_k(decay_alpha_ppo=multiplier_ppo, decay_alpha_rsi=multiplier_rsi, ppo_k=truncated_ppo_k, rsi_k=truncated_rsi_k, technical_data=truncated_technical_data, crashes_k=truncated_crashes_k)\\n        combined_k[\\'k\\'] = 0\\n        combined_k[\\'k\\'].loc[combined_k[\\'pos_k_hl_copy\\'] > combined_k[\\'neg_k_hl_copy\\']] = combined_k[\\'pos_k_hl_copy\\'] \\n        combined_k[\\'k\\'].loc[combined_k[\\'neg_k_hl_copy\\'] > combined_k[\\'pos_k_hl_copy\\']] = -1 * combined_k[\\'neg_k_hl_copy\\'] \\n\\n        combined_k[\\'k\\'] = combined_k[\\'k\\'].apply(closest_k)\\n        combined_k[\\'trading_action\\'] = 0\\n        combined_k[\\'trading_action\\'] = combined_k.apply(to_action, axis=1)\\n\\n        print(stock_symbol + \\'- ppo_decay : \\' + str(multiplier_ppo) + \\', rsi_decay : \\' + str(multiplier_rsi))\\n        profit = calculate_profit(combined_k)\\n        print(profit)\\n        \\n        if best_profit is None or profit > best_profit:\\n            best_profit = profit\\n            best_ppo_decay = multiplier_ppo\\n            best_rsi_decay = multiplier_rsi\\n        \\n        profits.append(profit)\\n\\n\\nprint(\"Best Profit: \" + str(best_profit))\\nprint(\"Best PPO_DECAY: \" + str(best_ppo_decay))\\nprint(\"Best RSI_DECAY: \" + str(best_rsi_decay))\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%timeit\n",
    "best_profit = None\n",
    "best_ppo_decay = None\n",
    "best_rsi_decay = None\n",
    "profits = []\n",
    "\n",
    "truncated_ppo_k = ppo_k[start_date_index:end_date_index+1].reset_index(drop=True)\n",
    "truncated_rsi_k = rsi_k[start_date_index:end_date_index+1].reset_index(drop=True)\n",
    "truncated_crashes_k = crashes_k[start_date_index:end_date_index+1].reset_index(drop=True)\n",
    "truncated_technical_data = technical_data[start_date_index:end_date_index+1].reset_index(drop=True)\n",
    "\n",
    "'''for multiplier_ppo in range(1, 30, 1):     \n",
    "    for multiplier_rsi in range(1, 30, 1): \n",
    "        combined_k = get_combined_k(decay_alpha_ppo=multiplier_ppo, decay_alpha_rsi=multiplier_rsi, ppo_k=truncated_ppo_k, rsi_k=truncated_rsi_k, technical_data=truncated_technical_data, crashes_k=truncated_crashes_k)\n",
    "        combined_k['k'] = 0\n",
    "        combined_k['k'].loc[combined_k['pos_k_hl_copy'] > combined_k['neg_k_hl_copy']] = combined_k['pos_k_hl_copy'] \n",
    "        combined_k['k'].loc[combined_k['neg_k_hl_copy'] > combined_k['pos_k_hl_copy']] = -1 * combined_k['neg_k_hl_copy'] \n",
    "\n",
    "        combined_k['k'] = combined_k['k'].apply(closest_k)\n",
    "        combined_k['trading_action'] = 0\n",
    "        combined_k['trading_action'] = combined_k.apply(to_action, axis=1)\n",
    "\n",
    "        print(stock_symbol + '- ppo_decay : ' + str(multiplier_ppo) + ', rsi_decay : ' + str(multiplier_rsi))\n",
    "        profit = calculate_profit(combined_k)\n",
    "        print(profit)\n",
    "        \n",
    "        if best_profit is None or profit > best_profit:\n",
    "            best_profit = profit\n",
    "            best_ppo_decay = multiplier_ppo\n",
    "            best_rsi_decay = multiplier_rsi\n",
    "        \n",
    "        profits.append(profit)\n",
    "\n",
    "\n",
    "print(\"Best Profit: \" + str(best_profit))\n",
    "print(\"Best PPO_DECAY: \" + str(best_ppo_decay))\n",
    "print(\"Best RSI_DECAY: \" + str(best_rsi_decay))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shift in patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig =plt.figure(figsize=(15,5))\n",
    "\n",
    "tmp_first = pd.read_csv(stock_symbol + '_25_to_725_profits.csv')\n",
    "tmp_second = pd.read_csv(stock_symbol + '_725_to_1425_profits.csv')\n",
    "#tmp_third = pd.read_csv(stock_symbol + '_1425_to_2125_profits.csv')\n",
    "\n",
    "first = (tmp_first - tmp_first.min())/(tmp_first.max() - tmp_first.min())\n",
    "second = (tmp_second - tmp_second.min())/(tmp_second.max() - tmp_second.min())\n",
    "#third = (tmp_third - tmp_third.min())/(tmp_third.max() - tmp_third.min())\n",
    "\n",
    "\n",
    "stop = len(first)\n",
    "plt.plot(range(len(first))[:stop], first['0'].as_matrix()[:stop], label='First 700 days', figure=fig)\n",
    "plt.plot(range(len(second))[:stop], second['0'].as_matrix()[:stop], label='Second 700 days', figure=fig)\n",
    "#plt.plot(range(len(third))[:stop], third['0'].as_matrix()[:stop], label='Third 700 days', figure=fig)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using trained nn model to predict regularizing parameters for PPO & RSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-b984f1dbba1a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnn_predicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./training_data/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstock_symbol\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_test_parameters.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32massert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtruncated_technical_data\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn_predicted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nn_predicted = pd.read_csv('./training_data/' + stock_symbol + '_test_parameters.csv')\n",
    "assert(len(truncated_technical_data) == len(nn_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_k = get_combined_k(decay_alpha_ppo=nn_predicted['ppo'], decay_alpha_rsi=nn_predicted['rsi'], ppo_k=truncated_ppo_k, rsi_k=truncated_rsi_k, technical_data=truncated_technical_data, crashes_k=truncated_crashes_k)\n",
    "combined_k['k'] = 0\n",
    "combined_k['k'].loc[combined_k['pos_k_hl_copy'] > combined_k['neg_k_hl_copy']] = combined_k['pos_k_hl_copy'] \n",
    "combined_k['k'].loc[combined_k['neg_k_hl_copy'] > combined_k['pos_k_hl_copy']] = -1 * combined_k['neg_k_hl_copy'] \n",
    "\n",
    "        \n",
    "combined_k['k'] = combined_k['k'].apply(closest_k)\n",
    "combined_k['trading_action'] = 0\n",
    "combined_k['trading_action'] = combined_k.apply(to_action, axis=1)\n",
    "\n",
    "profit = calculate_profit(combined_k)\n",
    "print(profit)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
