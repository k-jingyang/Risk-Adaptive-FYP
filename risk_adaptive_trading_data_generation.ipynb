{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trading System Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trader():\n",
    "    def __init__(self, stock_exchange, capital):\n",
    "        self.initial_capital = capital\n",
    "        self.cash = capital\n",
    "        self.portfolio = {}\n",
    "        self.exchange = stock_exchange\n",
    "        self.transaction_fees = 0.00175#0.002\n",
    "        \n",
    "    def buy(self, counter, size_to_buy):\n",
    "        # checks if counter even exists\n",
    "        if counter in self.exchange.get_available_counters():\n",
    "            # enough cash?\n",
    "            if self.exchange.get_price(counter) * size_to_buy <= self.cash:\n",
    "                self.cash -= (self.exchange.get_price(counter) * size_to_buy * (1+self.transaction_fees))\n",
    "                if counter not in self.portfolio.keys():\n",
    "                    self.portfolio[counter] = size_to_buy\n",
    "                else:\n",
    "                    self.portfolio[counter] += size_to_buy\n",
    "            else:\n",
    "                raise ValueError('Not enough money')\n",
    "            pass\n",
    "\n",
    "\n",
    "    def sell(self, counter, size_to_sell):\n",
    "        # checks if shares exists in trader's portfolio\n",
    "        if counter in self.portfolio.keys():\n",
    "            # enough shares?\n",
    "            if size_to_sell > 0:\n",
    "                if self.portfolio[counter] >= size_to_sell:\n",
    "                    #print(\"Cash before:\")\n",
    "                    #print(self.cash)\n",
    "                    self.portfolio[counter] -= size_to_sell\n",
    "                    #print(\"Cash gotten:\")\n",
    "                    #print(self.exchange.get_price(counter) * size_to_sell * (1-self.transaction_fees))\n",
    "                    self.cash += (self.exchange.get_price(counter) * size_to_sell * (1-self.transaction_fees))\n",
    "                    #print(\"Cash now:\")\n",
    "                    #print(self.cash)\n",
    "                else:\n",
    "                    raise ValueError('Not enough shares to sell')\n",
    "    def get_portfolio_value(self):\n",
    "        value = self.cash;\n",
    "        for i in self.portfolio.keys():\n",
    "            value = value + (self.portfolio[i] * self.exchange.get_price(i))\n",
    "            #print('Date: ' + str(self.exchange.get_date()))\n",
    "        return value\n",
    "    \n",
    "    def get_portfolio(self):\n",
    "        return self.portfolio\n",
    "    \n",
    "    def get_max_stocks_purchasable(self, counter, funds):\n",
    "        return math.floor(funds/((1+self.transaction_fees) * self.exchange.get_price(counter)))\n",
    "    \n",
    "    def get_cash(self):\n",
    "        return self.cash\n",
    "    \n",
    "    def get_initial_capital(self):\n",
    "        return self.initial_capital\n",
    "    \n",
    "    def get_profits(self):\n",
    "        return self.get_portfolio_value() - self.get_initial_capital()\n",
    "    \n",
    "    @staticmethod\n",
    "    def copy(trader):\n",
    "        new_trader = Trader(trader.exchange, trader.get_initial_capital())\n",
    "        new_trader.cash = trader.get_cash()\n",
    "        \n",
    "        if stock_symbol in trader.get_portfolio().keys():\n",
    "            new_trader.portfolio = { stock_symbol : trader.get_portfolio()[stock_symbol]}\n",
    "        else:\n",
    "            new_trader.portfolio = {}\n",
    "        new_trader.transaction_fees = 0.00175#0.002\n",
    "        return new_trader\n",
    "            \n",
    "class Stock_Exchange():\n",
    "    def __init__(self, counters):\n",
    "        self.available_counters = counters # takes a list, ['aig', 'bac', 'c', 'googl_v3', 'gs', 'jpm']\n",
    "        self.data = {}\n",
    "        self.date = datetime.datetime.strptime('2000-01-01', \"%Y-%m-%d\").date()\n",
    "        self.last_date = datetime.datetime.strptime('2020-01-01', \"%Y-%m-%d\").date()\n",
    "        for i in self.available_counters:\n",
    "            data = pd.read_csv('data/' + i + '.csv')\n",
    "            data['Date'] = data['Date'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%d\").date())\n",
    "            self.data[i] = data\n",
    "            if(self.date < self.data[i][\"Date\"][0]):\n",
    "                self.date = self.data[i][\"Date\"][0]\n",
    "                \n",
    "            if(self.last_date > self.data[i][\"Date\"].iloc[-1]):\n",
    "                self.last_date = self.data[i][\"Date\"].iloc[-1]\n",
    "        \n",
    "        self.first_date = self.date\n",
    "        \n",
    "    def get_available_counters(self):\n",
    "        return self.available_counters\n",
    "    \n",
    "    def get_price(self, counter):\n",
    "        if(counter in self.available_counters):\n",
    "            #print(self.data)\n",
    "            val = self.data[counter].loc[self.data[counter]['Date'] == self.date]['Close']\n",
    "            return list(val)[0]\n",
    "        else:\n",
    "            raise ValueError('Counter does not exist in exchange')\n",
    "            \n",
    "    def set_date(self, date, date_format):\n",
    "        date = datetime.datetime.strptime(date, date_format).date()\n",
    "        self.date = date\n",
    "        \n",
    "    def set_date(self, date):\n",
    "        self.date = date\n",
    "    \n",
    "    def get_date(self):\n",
    "        return self.date\n",
    "            \n",
    "    def next_day(self):\n",
    "        self.date = self.date + datetime.timedelta(days=1)\n",
    "        repeat = True\n",
    "        while repeat:\n",
    "            repeat = False\n",
    "            '''for i in self.available_counters:\n",
    "                if not (self.data[i]['Date'] == self.date).any():\n",
    "                    #print(self.date)\n",
    "                    #print('is a weekend')\n",
    "                    self.date = self.date + datetime.timedelta(days=1)\n",
    "                    repeat = True\n",
    "                    break\n",
    "            '''\n",
    "            if self.date.weekday() >= 5:\n",
    "                self.date = self.date + datetime.timedelta(days=1)\n",
    "                repeat = True\n",
    "    def get_last_date(self):\n",
    "        return self.last_date\n",
    "    \n",
    "    def get_first_date(self):\n",
    "        return self.first_date\n",
    "    \n",
    "    def reset(self):\n",
    "        self.date = self.first_date\n",
    "    \n",
    "    def fast_forward(self):\n",
    "        self.date = self.last_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_processed_data(technical_indicated_file):\n",
    "    std_span = 10\n",
    "    # Data reading and preprocessing\n",
    "    data =  pd.read_csv(technical_indicated_file)\n",
    "    data['Date'] = data['Date'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%d\").date())\n",
    "    small_data = data\n",
    "    x = small_data['Date']\n",
    "\n",
    "    # Calculating std (sigma)\n",
    "    std = pd.DataFrame()\n",
    "    std['Date'] = small_data['Date']\n",
    "    std['Rolling-STD'] = small_data[\"EMA-12-Close\"].rolling(std_span).std()\n",
    "    \n",
    "    # PCT_CHANGE\n",
    "    small_data['Pct_Change'] = small_data['EMA-12-Close'].pct_change()\n",
    "    small_data['Abs_Pct_Change'] = abs(small_data['EMA-12-Close'].pct_change())\n",
    "    small_data['Pct_Change_Vol'] = small_data['EMA-12-Volume'].pct_change()\n",
    "\n",
    "    \"\"\"\n",
    "    Calculating volatility\n",
    "    \"\"\"\n",
    "    crashes_k = pd.DataFrame()\n",
    "    crashes_k[\"Date\"] = small_data[\"Date\"]\n",
    "    crashes_k[\"crashes_k\"] = small_data['neg_and_above_threshold'] * 1\n",
    "\n",
    "\n",
    "    \"\"\" \n",
    "    Using PPO for Timing\n",
    "    \"\"\"\n",
    "    # neg_k = 1 when trigger goes on top of PPO line (Red)\n",
    "    # pos_k = 1 when trigger goes below PPO line (Green)\n",
    "\n",
    "    d = (small_data[\"PPO\"] - small_data[\"PPO-EMA-Trigger\"])\n",
    "\n",
    "    # PPO Buy and Sell Signals\n",
    "    ppo_above = pd.Series(np.nan, index=list(range(0,small_data.shape[0])))\n",
    "    ppo_below = pd.Series(np.nan, index=list(range(0,small_data.shape[0])))\n",
    "    ppo_buy_signals = pd.Series(np.nan, index=list(range(0,small_data.shape[0])))\n",
    "    ppo_sell_signals = pd.Series(np.nan, index=list(range(0,small_data.shape[0])))\n",
    "\n",
    "\n",
    "    d = (small_data[\"PPO\"] - small_data[\"PPO-EMA-Trigger\"])\n",
    "    for i in range(1, len(d) - 1):\n",
    "        if d[i] * d[i - 1] < 0.:\n",
    "            # crossover at i\n",
    "            if(d[i] > 0.):\n",
    "                ppo_above[i] = small_data.loc[i, \"PPO-EMA-Trigger\"]\n",
    "                ppo_buy_signals[i] = small_data.loc[i, \"Date\"]\n",
    "            else:\n",
    "                ppo_below[i] = small_data.loc[i, \"PPO-EMA-Trigger\"]\n",
    "                ppo_sell_signals[i] = small_data.loc[i, \"Date\"]\n",
    "\n",
    "    #ppo_buy_signals.to_csv(folder + counter + \"-ppo-buy.csv\", index=False)\n",
    "    #ppo_sell_signals.to_csv(folder + counter + \"-ppo-sell.csv\", index=False)\n",
    "\n",
    "\n",
    "    # Caclulating ppo_k\n",
    "    ppo_k = pd.DataFrame()\n",
    "\n",
    "    # Populating std\n",
    "    ppo_k['std'] = std['Rolling-STD']\n",
    "\n",
    "    # Filling pos_k and neg_k with 1\n",
    "    ppo_k[\"Date\"] = small_data[\"Date\"]\n",
    "    ppo_k[\"pos_k\"] = pd.Series(np.nan, index=list(range(0,ppo_k.shape[0])))\n",
    "    ppo_k[\"pos_k\"].loc[ppo_k[\"Date\"] == ppo_buy_signals] = 1\n",
    "\n",
    "    ppo_k[\"neg_k\"] = pd.Series(np.nan, index=list(range(0,ppo_k.shape[0])))\n",
    "    ppo_k[\"neg_k\"].loc[ppo_k[\"Date\"] == ppo_sell_signals] = 1\n",
    "    assert(all(std[\"Date\"] == ppo_k[\"Date\"]))\n",
    "\n",
    "    # Filling ppo_k dataframe with t to help speed up calculation during half-life\n",
    "    # Init t as 0 for dates where ppo signals\n",
    "    ppo_k[\"pos_k_t\"] = pd.Series(np.nan, index=list(range(0,ppo_k.shape[0])))\n",
    "    ppo_k[\"pos_k_t\"].loc[ppo_k[\"pos_k\"] == 1] = 0\n",
    "\n",
    "    ppo_k[\"neg_k_t\"] = pd.Series(np.nan, index=list(range(0,ppo_k.shape[0])))\n",
    "    ppo_k[\"neg_k_t\"].loc[ppo_k[\"neg_k\"] == 1] = 0\n",
    "\n",
    "    # Identify first pos_k and first neg_k\n",
    "    first_pos_k_index = ppo_k['pos_k'].idxmax()\n",
    "    first_neg_k_index = ppo_k['neg_k'].idxmax()\n",
    "\n",
    "    # Populating ppo t values \n",
    "    tmp = ppo_k.copy()\n",
    "    i = 0\n",
    "    while ppo_k[\"pos_k_t\"][first_pos_k_index:].isnull().values.any() or ppo_k[\"neg_k_t\"][first_neg_k_index:].isnull().values.any():\n",
    "        i+=1\n",
    "        tmp = tmp.shift()\n",
    "        ppo_k[\"pos_k_t\"].loc[(tmp[\"pos_k\"] == 1) & (ppo_k[\"pos_k_t\"].isnull())] = i\n",
    "        ppo_k[\"neg_k_t\"].loc[(tmp[\"neg_k\"] == 1) & (ppo_k[\"neg_k_t\"].isnull())] = i\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Using RSI for Timing\n",
    "    \"\"\"\n",
    "    # neg_k = 1 when above 70 (Overbought)\n",
    "    # pos_k = 1 when above 30 (Oversold)\n",
    "    overbought = pd.Series(np.nan, index=list(range(0,small_data.shape[0])))\n",
    "    oversold = pd.Series(np.nan, index=list(range(0,small_data.shape[0])))\n",
    "    rsi_buy_signals = pd.Series(np.nan, index=list(range(0,small_data.shape[0])))\n",
    "    rsi_sell_signals = pd.Series(np.nan, index=list(range(0,small_data.shape[0])))\n",
    "\n",
    "    d_overbought = (70 - small_data[\"RSI\"])\n",
    "    for i in range(1, len(d_overbought) - 1):\n",
    "        '''if d_overbought[i] * d_overbought[i - 1] < 0.:\n",
    "                # crossover at i\n",
    "                if d_overbought[i] < 0.:\n",
    "                    rsi_sell_signals[i] = small_data.loc[i, \"Date\"]\n",
    "                    overbought[i] = 70 #small_data.loc[i, \"RSI\"]'''\n",
    "        if(d_overbought[i] < 0):\n",
    "            rsi_sell_signals[i] = small_data.loc[i, \"Date\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    d_oversold = (30 - small_data[\"RSI\"])\n",
    "    for i in range(1, len(d_oversold) - 1):\n",
    "        '''if d_oversold[i] * d_oversold[i - 1] < 0.:\n",
    "                # crossover at i\n",
    "                if d_oversold[i] > 0.:\n",
    "                    rsi_buy_signals[i] = small_data.loc[i, \"Date\"]\n",
    "                    oversold[i] = 30 #small_data.loc[i, \"RSI\"]'''\n",
    "        if(d_oversold[i] > 0):\n",
    "            rsi_buy_signals[i] = small_data.loc[i, \"Date\"]\n",
    "\n",
    "\n",
    "\n",
    "    # Caclulating rsi_k\n",
    "    rsi_k = pd.DataFrame()\n",
    "\n",
    "    # Populating std\n",
    "    rsi_k['std'] = std['Rolling-STD']\n",
    "\n",
    "    # Filling pos_k and neg_k with 1\n",
    "    rsi_k[\"Date\"] = small_data[\"Date\"]\n",
    "    rsi_k[\"pos_k\"] = pd.Series(np.nan, index=list(range(0,rsi_k.shape[0])))\n",
    "    rsi_k[\"pos_k\"].loc[rsi_k[\"Date\"] == rsi_buy_signals] = 1\n",
    "\n",
    "    rsi_k[\"neg_k\"] = pd.Series(np.nan, index=list(range(0,rsi_k.shape[0])))\n",
    "    rsi_k[\"neg_k\"].loc[rsi_k[\"Date\"] == rsi_sell_signals] = 1\n",
    "    assert(all(std[\"Date\"] == rsi_k[\"Date\"]))\n",
    "\n",
    "\n",
    "    # Filling rsi_k dataframe with t to help speed up calculation during half-life\n",
    "    # Init t as 0 for dates where rsi signals\n",
    "    rsi_k[\"pos_k_t\"] = pd.Series(np.nan, index=list(range(0,rsi_k.shape[0])))\n",
    "    rsi_k[\"pos_k_t\"].loc[rsi_k[\"pos_k\"] == 1] = 0\n",
    "\n",
    "    rsi_k[\"neg_k_t\"] = pd.Series(np.nan, index=list(range(0,rsi_k.shape[0])))\n",
    "    rsi_k[\"neg_k_t\"].loc[rsi_k[\"neg_k\"] == 1] = 0\n",
    "\n",
    "    # Identify first pos_k and first neg_k\n",
    "    first_pos_k_index = rsi_k['pos_k'].idxmax()\n",
    "    first_neg_k_index = rsi_k['neg_k'].idxmax()\n",
    "\n",
    "    # Populating rsi t values \n",
    "    tmp = rsi_k.copy()\n",
    "    i = 0\n",
    "    while rsi_k[\"pos_k_t\"][first_pos_k_index:].isnull().values.any() or rsi_k[\"neg_k_t\"][first_neg_k_index:].isnull().values.any():\n",
    "        i+=1\n",
    "        tmp = tmp.shift()\n",
    "        rsi_k[\"pos_k_t\"].loc[(tmp[\"pos_k\"] == 1) & (rsi_k[\"pos_k_t\"].isnull())] = i\n",
    "        rsi_k[\"neg_k_t\"].loc[(tmp[\"neg_k\"] == 1) & (rsi_k[\"neg_k_t\"].isnull())] = i\n",
    "    \n",
    "    return ppo_k, rsi_k, crashes_k, small_data, ppo_buy_signals, ppo_sell_signals\n",
    "\n",
    "def get_combined_k(decay_alpha_ppo, decay_alpha_rsi, ppo_k, rsi_k, technical_data, crashes_k):\n",
    "    \"\"\"\n",
    "    Generate combined pos_k and neg_k based on given decay_alpha\n",
    "    \"\"\"\n",
    "    \n",
    "    assert(len(ppo_k) == len(rsi_k) and len(technical_data) == len(crashes_k) and len(technical_data == len(ppo_k)))\n",
    "    \n",
    "    # Decay ppo_k using half-life \n",
    "    ppo_k[\"pos_k_hl\"] = ppo_k[\"pos_k\"]\n",
    "    ppo_k[\"neg_k_hl\"] = ppo_k[\"neg_k\"]\n",
    "\n",
    "    tmp = (-1 * decay_alpha_ppo * technical_data['Abs_Pct_Change'])\n",
    "    \n",
    "    ppo_k[\"pos_k_hl\"] = (math.e ** (tmp * ppo_k[\"pos_k_t\"])) # * 1.0 (omitted) where 1.0 is the N(0)\n",
    "    ppo_k[\"neg_k_hl\"] = (math.e ** (tmp * ppo_k[\"neg_k_t\"])) # * 1.0 (omitted) where 1.0 is the N(0)\n",
    "    \n",
    "    '''ppo_k[\"pos_k_hl\"] = 1.0 * (math.e ** (-1 * decay_alpha_ppo * (technical_data['pct_change_vol'] * 1000) * technical_data['pct_change'] * ppo_k[\"pos_k_t\"])) \n",
    "    ppo_k[\"neg_k_hl\"] = 1.0 * (math.e ** (-1 * decay_alpha_ppo * (technical_data['pct_change_vol'] * 1000) * technical_data['pct_change'] * ppo_k[\"neg_k_t\"]))\n",
    "    '''\n",
    "    # Decay rsi_k using half-life \n",
    "    rsi_k[\"pos_k_hl\"] = rsi_k[\"pos_k\"]\n",
    "    rsi_k[\"neg_k_hl\"] = rsi_k[\"neg_k\"]\n",
    "    \n",
    "    tmp = (-1 * decay_alpha_rsi * technical_data['Abs_Pct_Change'])\n",
    "\n",
    "    rsi_k[\"pos_k_hl\"] = (math.e ** (tmp * rsi_k[\"pos_k_t\"])) # * 1.0 (omitted) where 1.0 is the N(0)\n",
    "    rsi_k[\"neg_k_hl\"] = (math.e ** (tmp * rsi_k[\"neg_k_t\"])) # * 1.0 (omitted) where 1.0 is the N(0)\n",
    "    \n",
    "    '''rsi_k[\"pos_k_hl\"] = 1.0 * (math.e ** (-1 * decay_alpha_rsi * (technical_data['pct_change_vol'] * 1000) * technical_data['pct_change'] * rsi_k[\"pos_k_t\"])) \n",
    "    rsi_k[\"neg_k_hl\"] = 1.0 * (math.e ** (-1 * decay_alpha_rsi * (technical_data['pct_change_vol'] * 1000) * technical_data['pct_change'] * rsi_k[\"neg_k_t\"]))\n",
    "    '''\n",
    "    #print(rsi_k[\"pos_k_hl\"])\n",
    "    #rsi_k.to_csv(folder + counter + \"-rsi.csv\")\n",
    "    #ppo_k.to_csv(folder + counter + \"-ppo.csv\")\n",
    "\n",
    "    # Combining PPO_K and RSI_K\n",
    "    assert(all(ppo_k[\"Date\"] == rsi_k[\"Date\"]) and all(ppo_k[\"Date\"] == technical_data[\"Date\"]) and all(crashes_k[\"Date\"] == ppo_k[\"Date\"]))\n",
    "    \n",
    "    combined_k = pd.DataFrame()\n",
    "    combined_k[\"Date\"] = technical_data[\"Date\"]\n",
    "    combined_k[\"pos_k_hl\"] = ppo_k[\"pos_k_hl\"].fillna(0) * rsi_k[\"pos_k_hl\"].fillna(0)\n",
    "    combined_k[\"neg_k_hl\"] = pow(ppo_k[\"neg_k_hl\"].fillna(0) * rsi_k[\"neg_k_hl\"].fillna(0), 1-crashes_k[\"crashes_k\"])\n",
    "    #combined_k[\"neg_k_hl\"] = ppo_k[\"neg_k_hl\"].fillna(0) * rsi_k[\"neg_k_hl\"].fillna(0)\n",
    "\n",
    "\n",
    "    # Using ADX & DMI\n",
    "    # Irrespective of whether the trader takes a long or short position, \n",
    "    # the ADX should be over 25 when the crossover occurs to confirm the trendâ€™s strength. \n",
    "    combined_k[\"pos_k_hl_copy\"] = combined_k[\"pos_k_hl\"]\n",
    "    combined_k[\"neg_k_hl_copy\"] = combined_k[\"neg_k_hl\"]\n",
    "\n",
    "    assert(all(combined_k[\"Date\"]==technical_data[\"Date\"]))\n",
    "\n",
    "    combined_k[\"neg_k_hl_copy\"].loc[(technical_data[\"NEG_DI14\"] > technical_data[\"POS_DI14\"]) & (technical_data[\"ADX\"] >= 20)] = combined_k[\"neg_k_hl\"] * 0.25\n",
    "    combined_k[\"neg_k_hl_copy\"].loc[(technical_data[\"NEG_DI14\"] > technical_data[\"POS_DI14\"]) & (technical_data[\"ADX\"] >= 30)] = combined_k[\"neg_k_hl\"] * 0.5\n",
    "    combined_k[\"neg_k_hl_copy\"].loc[(technical_data[\"NEG_DI14\"] > technical_data[\"POS_DI14\"]) & (technical_data[\"ADX\"] >= 40)] = combined_k[\"neg_k_hl\"] * 1.0\n",
    "    \n",
    "    combined_k[\"pos_k_hl_copy\"].loc[(technical_data[\"POS_DI14\"] > technical_data[\"NEG_DI14\"]) & (technical_data[\"ADX\"] >= 20)] = combined_k[\"pos_k_hl\"] * 0.25\n",
    "    combined_k[\"pos_k_hl_copy\"].loc[(technical_data[\"POS_DI14\"] > technical_data[\"NEG_DI14\"]) & (technical_data[\"ADX\"] >= 30)] = combined_k[\"pos_k_hl\"] * 0.5\n",
    "    combined_k[\"pos_k_hl_copy\"].loc[(technical_data[\"POS_DI14\"] > technical_data[\"NEG_DI14\"]) & (technical_data[\"ADX\"] >= 40)] = combined_k[\"pos_k_hl\"] * 1.0\n",
    "    \n",
    "    # Make it mutually exlusive\n",
    "    combined_k[\"neg_k_hl_copy\"].loc[(technical_data[\"POS_DI14\"] > technical_data[\"NEG_DI14\"]) & (technical_data[\"ADX\"] > 20)] = 0\n",
    "    combined_k[\"pos_k_hl_copy\"].loc[(technical_data[\"POS_DI14\"] < technical_data[\"NEG_DI14\"]) & (technical_data[\"ADX\"] > 20)] = 0\n",
    "\n",
    "    # Trend not strong enough\n",
    "    combined_k[\"neg_k_hl_copy\"].loc[(technical_data[\"ADX\"] < 20)] = 0\n",
    "    combined_k[\"pos_k_hl_copy\"].loc[(technical_data[\"ADX\"] < 20)] = 0\n",
    "\n",
    "    # combined_k.to_csv(folder + counter + \"-combined.csv\", index=False)\n",
    "    return combined_k\n",
    "\n",
    "def calculate_profit(a_trading_pattern):\n",
    "    mock_trader = Trader(secondary_exchange, capital)\n",
    "    trade(a_trading_pattern, mock_trader)\n",
    "    return mock_trader.get_portfolio_value() - mock_trader.get_initial_capital()\n",
    "    \n",
    "\n",
    "def trade(a_trading_pattern, mock_trader):\n",
    "    for index, row in a_trading_pattern.iterrows():\n",
    "        secondary_exchange.set_date(row['Date'])\n",
    "        if row['trading_action'] == ACTION_LONG:\n",
    "            stocks_to_buy = mock_trader.get_max_stocks_purchasable(stock_symbol, mock_trader.get_cash())\n",
    "            mock_trader.buy(stock_symbol, stocks_to_buy)\n",
    "        elif row['trading_action'] == ACTION_CLOSE:\n",
    "            if stock_symbol in mock_trader.get_portfolio().keys():\n",
    "                mock_trader.sell(stock_symbol, mock_trader.get_portfolio()[stock_symbol])\n",
    "                \n",
    "def closest_k(k):\n",
    "    closest_risk = None\n",
    "    closest_distance = None\n",
    "    for risk_level in risk_levels:\n",
    "        distance = abs(k-risk_level)\n",
    "        if closest_risk is None or distance < closest_distance:\n",
    "            closest_distance = distance\n",
    "            closest_risk = risk_level\n",
    "    return closest_risk\n",
    "\n",
    "def to_action(row):\n",
    "    date = row['Date']\n",
    "    risk_level = row['k']\n",
    "    tmp_pattern = trading_patterns_dict[risk_level]\n",
    "    return tmp_pattern[date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import math\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "PARAMETERS TO CHANGE\n",
    "'''\n",
    "stock_symbol = 'c'\n",
    "window_size = 25 # change to 10\n",
    "get_optimal_values = False # This takes a long time...\n",
    "generate_training_data = False\n",
    "generate_test_data = True\n",
    "to_resume = True\n",
    "\n",
    "## RESUME function badly written. Please be understanding. Hahaha.\n",
    "resume_from_window = 25 # will start from this window, minimum is window_size\n",
    "\n",
    "start_price_indexes = [25, 725, 1425] # this should be (25 + start_state_num from the risk_q_learning file)\n",
    "if generate_test_data:\n",
    "    start_price_indexes = [2125]\n",
    "\n",
    "''''''\n",
    "\n",
    "\n",
    "assert(not (generate_training_data & generate_test_data)) # Can be both False\n",
    "\n",
    "risk_levels = [-1, -0.5, -0.2, 0, 0.2, 0.5, 1]\n",
    "\n",
    "ACTION_LONG = 0\n",
    "ACTION_CLOSE = 1\n",
    "\n",
    "\n",
    "\n",
    "duration_for_each = 700 # this should be the same as the duration in risk_q_learning\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "assert(resume_from_window >= window_size)\n",
    "trading_patterns_dir = './trading_patterns/'\n",
    "training_data_dir = './training_data/'\n",
    "trading_patterns = []\n",
    "trading_patterns_dict = {}\n",
    "\n",
    "dates = []\n",
    "populated_dates = False\n",
    "for level in risk_levels:    \n",
    "    trading_patterns_dict[level] = {}\n",
    "    \n",
    "    for start_price_index in start_price_indexes:\n",
    "        actions_data = pd.read_csv(trading_patterns_dir + stock_symbol + '_' + str(level) + '_' + str(start_price_index) + '_to_' + str(start_price_index + duration_for_each) + '.csv')\n",
    "        actions_data['Date'] = actions_data['Date'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%d\").date())\n",
    "\n",
    "        for index, row in actions_data[start_price_index:start_price_index+duration_for_each].iterrows():\n",
    "            trading_patterns_dict[level][row['Date']] = row['trading_action']\n",
    "            if populated_dates is False:\n",
    "                dates.append(row['Date'])\n",
    "    populated_dates = True\n",
    "exchange = Stock_Exchange([stock_symbol])\n",
    "secondary_exchange = Stock_Exchange([stock_symbol])\n",
    "capital = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jing yang\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pandas\\core\\indexing.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "exchange.reset()\n",
    "jingyang = Trader(exchange, capital)\n",
    "folder = \"./temp/\"\n",
    "ppo_k, rsi_k, crashes_k, technical_data, tmp_ppo_buy_dates, tmp_ppo_sell_dates = get_processed_data(folder+stock_symbol+'-technical-indicated.csv')\n",
    "\n",
    "tmp_start_date = dates[0]\n",
    "tmp_end_date = dates[-1]\n",
    "\n",
    "start_date_index = technical_data.index[technical_data['Date'] == tmp_start_date].tolist()[0] \n",
    "end_date_index = technical_data.index[technical_data['Date'] == tmp_end_date].tolist()[0] \n",
    "\n",
    "truncated_ppo_k = ppo_k[start_date_index:end_date_index+1].reset_index(drop=True)\n",
    "truncated_rsi_k = rsi_k[start_date_index:end_date_index+1].reset_index(drop=True)\n",
    "truncated_crashes_k = crashes_k[start_date_index:end_date_index+1].reset_index(drop=True)\n",
    "truncated_technical_data = technical_data[start_date_index:end_date_index+1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal parameters per window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data production\n",
    "resumed = False\n",
    "\n",
    "\n",
    "if get_optimal_values:\n",
    "\n",
    "    assert(len(truncated_ppo_k) % window_size == 0)\n",
    "\n",
    "    start_regularizer = 1\n",
    "    end_regularizer = 25\n",
    "\n",
    "    training_data = {}\n",
    "    training_data['window'] = []\n",
    "    training_data['ppo'] = []\n",
    "    training_data['rsi'] = []\n",
    "\n",
    "    for k in range(0, 3): # for k in range(0, window_size) by right\n",
    "\n",
    "        optimal_trader = Trader(secondary_exchange, capital)\n",
    "\n",
    "        for i in range(k+window_size, len(truncated_ppo_k), window_size):\n",
    "            \n",
    "            if not resumed:\n",
    "                if to_resume:\n",
    "                    if i == resume_from_window:\n",
    "                        training_data = pd.read_csv(training_data_dir+stock_symbol+'_optimal_parameters.csv').to_dict('list')\n",
    "                        resumed = True\n",
    "                        \n",
    "                        if resume_from_window > window_size:\n",
    "                            with open('saved_trader.pkl', 'rb') as input:\n",
    "                                window_best_trader = pickle.load(input)\n",
    "                                print(window_best_trader.get_profits())\n",
    "                    \n",
    "                else:\n",
    "                    resumed = True\n",
    "            if resumed:\n",
    "                window_truncated_ppo_k = truncated_ppo_k[i:i+window_size]\n",
    "                window_truncated_rsi_k = truncated_rsi_k[i:i+window_size]\n",
    "                window_truncated_crashes_k = truncated_crashes_k[i:i+window_size]\n",
    "                window_truncated_technical_data = truncated_technical_data[i:i+window_size]\n",
    "\n",
    "                window_best_trader = None\n",
    "                window_best_profits = None\n",
    "                best_ppo = None\n",
    "                best_rsi = None\n",
    "\n",
    "                for multiplier_ppo in range(start_regularizer, end_regularizer, 1):     \n",
    "                    for multiplier_rsi in range(start_regularizer, end_regularizer, 1): \n",
    "\n",
    "                        tmp_trader = Trader.copy(optimal_trader)\n",
    "                        combined_k = get_combined_k(decay_alpha_ppo=multiplier_ppo, decay_alpha_rsi=multiplier_rsi, ppo_k=window_truncated_ppo_k, rsi_k=window_truncated_rsi_k, technical_data=window_truncated_technical_data, crashes_k=window_truncated_crashes_k)\n",
    "                        combined_k['k'] = 0\n",
    "                        combined_k['k'].loc[combined_k['pos_k_hl_copy'] > combined_k['neg_k_hl_copy']] = combined_k['pos_k_hl_copy'] \n",
    "                        combined_k['k'].loc[combined_k['neg_k_hl_copy'] > combined_k['pos_k_hl_copy']] = -1 * combined_k['neg_k_hl_copy'] \n",
    "\n",
    "                        combined_k['k'] = combined_k['k'].apply(closest_k)\n",
    "                        combined_k['trading_action'] = 0\n",
    "                        combined_k['trading_action'] = combined_k.apply(to_action, axis=1)\n",
    "\n",
    "                        trade(combined_k, tmp_trader)\n",
    "\n",
    "                        profit = tmp_trader.get_profits()\n",
    "\n",
    "                        if window_best_trader is None or profit > window_best_profits:\n",
    "                            window_best_trader = tmp_trader\n",
    "                            window_best_profits = profit\n",
    "                            best_ppo = multiplier_ppo\n",
    "                            best_rsi = multiplier_rsi\n",
    "\n",
    "\n",
    "                        #print(stock_symbol + '- ppo_decay : ' + str(multiplier_ppo) + ', rsi_decay : ' + str(multiplier_rsi))    \n",
    "                        #print(profit)\n",
    "\n",
    "                training_data['window'].append(i-window_size+start_price_indexes[0]-25)\n",
    "                training_data['ppo'].append(best_ppo)\n",
    "                training_data['rsi'].append(best_rsi)\n",
    "                print('best profit after window: ' + str(i-window_size+start_price_indexes[0]-25) + \"/\" + str(len(truncated_ppo_k)))\n",
    "                print(window_best_trader.get_profits())\n",
    "                print('cash:' + str(window_best_trader.get_cash()))\n",
    "                print('stocks:' + str(window_best_trader.get_portfolio()))\n",
    "                \n",
    "                with open('saved_trader.pkl', 'wb') as output:\n",
    "                    pickle.dump(window_best_trader, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "                \n",
    "                print(\"If you stop here. Resume using resume_from_window=\" + str(i+window_size+start_price_indexes[0]-25))\n",
    "                optimal_trader = Trader.copy(window_best_trader)\n",
    "\n",
    "                # Save results\n",
    "                pd.DataFrame(training_data).to_csv(training_data_dir+stock_symbol+'_optimal_parameters.csv', index=False)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if generate_training_data or generate_test_data:\n",
    "    \n",
    "    features_dict = {}\n",
    "    \n",
    "    # What you want to use as features, and should correspond to technical_data's column names\n",
    "    features = ['Pct_Change_Vol']#['Pct_Change', 'Pct_Change_Vol'] \n",
    "    \n",
    "    \n",
    "    if generate_test_data:\n",
    "        features_dict['Date_to_use_on'] = []\n",
    "    \n",
    "    for i in range(1, window_size+1):\n",
    "        for features_i in features:\n",
    "            features_dict[features_i+'_'+str(i)] = []\n",
    "    \n",
    "    if generate_test_data:\n",
    "        \n",
    "        for window in range(0, len(truncated_technical_data)-window_size):\n",
    "            for i in range(window_size):\n",
    "                index_to_retrieve = window + i\n",
    "                \n",
    "                for features_i in features:\n",
    "                    features_dict[features_i+'_'+str(i+1)].append(truncated_technical_data[features_i][index_to_retrieve])\n",
    "            \n",
    "            features_dict['Date_to_use_on'].append(truncated_technical_data['Date'][window+window_size])\n",
    "        test_data = pd.DataFrame(features_dict) \n",
    "        test_data.to_csv(training_data_dir+stock_symbol+'_test_data.csv', index=False)\n",
    "        \n",
    "    if generate_training_data:    \n",
    "        features_dict['window'] = []\n",
    "        optimal_parameters = pd.read_csv(training_data_dir + stock_symbol+'_optimal_parameters.csv')\n",
    "        for index, row in optimal_parameters.iterrows():\n",
    "            window = row['window']\n",
    "\n",
    "            features_dict['window'].append(window)\n",
    "            for i in range(window_size):\n",
    "                index_to_retrieve = window + i\n",
    "\n",
    "                for features_i in features:\n",
    "                    features_dict[features_i+'_'+str(i+1)].append(truncated_technical_data[features_i][index_to_retrieve])\n",
    "\n",
    "        features_df = pd.DataFrame(features_dict)\n",
    "        \n",
    "        training_data = pd.merge(optimal_parameters, features_df)\n",
    "        training_data.to_csv(training_data_dir+stock_symbol+'_training_data.csv', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
